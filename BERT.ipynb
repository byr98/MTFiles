{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "import nlpaug.augmenter.word as naw\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import emoji\n",
    "import unicodedata\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from collections import Counter\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\buket\\Desktop\\Bayar_Thesis\\original_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priority Column Preprocessing\n",
    "##### Based on the approach Mapping should be changed and data = data[data['priority'] != 'P3'] should be dropped or kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping logic\n",
    "data = data[data['priority'] != '--'] #always drop '--'\n",
    "data = data[data['priority'] != 'P3'] \n",
    "priority_mapping = {\n",
    "    'P1': 0,  \n",
    "    'P2': 0,  \n",
    "    'P4': 1,  \n",
    "    'P5': 2   \n",
    "}\n",
    "\n",
    "\n",
    "data['priority'] = data['priority'].map(priority_mapping)\n",
    "\n",
    "print(data['priority'].value_counts())\n",
    "\n",
    "unique_count = data['priority'].nunique()\n",
    "print(f\"Number of unique values: {unique_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing and Categorical Values in Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['severity'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['severity'].value_counts(dropna=False))\n",
    "\n",
    "# Drop rows with NaN values in the 'severity' column\n",
    "data = data.dropna(subset=['severity'])\n",
    "\n",
    "print(data['severity'].value_counts())\n",
    "print(f\"Updated dataset shape: {data.shape}\")\n",
    "\n",
    "# Severity mapping based on the website\n",
    "severity_mapping = {\n",
    "    'S2': 2,       # Major\n",
    "    'S1': 1,       # Critical\n",
    "    'S3': 3,       # Normal\n",
    "    'S4': 4,       # Minor\n",
    "    'normal': 3,   # Normal\n",
    "    'major': 2,    # Major\n",
    "    'minor': 4,    # Minor\n",
    "    'critical': 1, # Critical\n",
    "    'trivial': 4,  # Minor\n",
    "    'blocker': 1   # Critical\n",
    "}\n",
    "\n",
    "data['severity_mapped'] = data['severity'].map(severity_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[['severity', 'severity_mapped']].head())\n",
    "\n",
    "print(data['severity_mapped'].unique())\n",
    "print(data['severity_mapped'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting and Extracting Features from Creation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'creation_time' to datetime\n",
    "data['creation_time'] = pd.to_datetime(data['creation_time'])\n",
    "\n",
    "print(data['creation_time'].head())\n",
    "print(data['creation_time'].dtypes)\n",
    "\n",
    "# Get the maximum creation time from the dataset as the reference date\n",
    "reference_date = data['creation_time'].max()\n",
    "print(f\"Reference date: {reference_date}\")\n",
    "\n",
    "# Calculate bug age in days\n",
    "data['bug_age'] = (reference_date - data['creation_time']).dt.days\n",
    "print(data[['creation_time', 'bug_age']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Product Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_counts = data['product'].value_counts()\n",
    "\n",
    "# Define the threshold for grouping smaller categories\n",
    "threshold = 100\n",
    "data['product'] = data['product'].apply(lambda x: x if product_counts[x] >= threshold else 'Other')\n",
    "\n",
    "# Recalculate value counts after grouping smaller categories\n",
    "updated_product_counts = data['product'].value_counts()\n",
    "\n",
    "# Percentage of bugs grouped under \"Other\"\n",
    "other_percentage = (updated_product_counts['Other'] / len(data)) * 100\n",
    "\n",
    "updated_product_counts, other_percentage\n",
    "\n",
    "unique_count = data['product'].nunique()\n",
    "print(f\"Number of unique values: {unique_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Textual Columns\n",
    "##### Not dropping the missing values in the description column here since they will be merged with the summary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Missing values in 'description': {data['description'].isnull().sum()}\")\n",
    "data['description'] = data['description'].fillna('')\n",
    "print(f\"Missing values in 'description': {data['description'].isnull().sum()}\")\n",
    "\n",
    "# Merge the 'summary' and 'description' columns\n",
    "data['merged_summary_description'] = data['summary'] + \" \" + data['description']\n",
    "\n",
    "print(data[['summary', 'description', 'merged_summary_description']].head())\n",
    "\n",
    "print(f\"Missing values in 'merged_summary_description': {data['merged_summary_description'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns\n",
    "data = data.drop(['summary', 'creation_time', 'id', 'description', 'severity'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning: Replacing Contractions and Removing Special Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Replacing Contractions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regular expression pattern with replacements\n",
    "def replace_contractions(text):\n",
    "    contractions = {\n",
    "        r\"don´t\": \"do not\",\n",
    "        r\"isn´t\": \"is not\",\n",
    "        r\"hasn´t\": \"has not\",\n",
    "        r\"doesn´t\": \"does not\",\n",
    "        r\"haven´t\": \"have not\",\n",
    "        r\"aren´t\": \"are not\",\n",
    "        r\"couldn´t\": \"could not\",\n",
    "        r\"can´t\": \"can not\"\n",
    "    }\n",
    "    # Compile a regex pattern\n",
    "    pattern = re.compile(\"|\".join(contractions.keys()), flags=re.IGNORECASE)\n",
    "    return pattern.sub(lambda x: contractions[x.group().lower()], text)\n",
    "\n",
    "# Apply the function to the DataFrame column\n",
    "data['merged_summary_description'] = data['merged_summary_description'].apply(replace_contractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cleaning Special Characters and Numbers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cleaning functions\n",
    "def remove_html_tags(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_urls(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "\n",
    "def remove_emails(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return re.sub(r\"[a-zA-Z0-9\\.\\-+_]+@[a-zA-Z0-9\\.\\-+_]+\\.[a-zA-Z]+\",'',text)\n",
    "\n",
    "def remove_control_characters(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return emoji.replace_emoji(text, replace=\"\")\n",
    "\n",
    "def remove_punctuation_except_commas_periods(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    translator = str.maketrans('', '', string.punctuation.replace(\",\", \"\").replace(\".\", \"\"))\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return ''.join(i for i in text if ord(i)<128)\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return unicodedata.normalize('NFKC', text)\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def preprocessor(text_or_series):\n",
    "    if isinstance(text_or_series, pd.Series):\n",
    "        return text_or_series.apply(lambda text: normalize_whitespace(normalize_unicode(remove_non_ascii(remove_punctuation_except_commas_periods(remove_emojis(remove_control_characters(remove_emails(remove_urls(remove_html_tags(str(text)))))))))))\n",
    "    elif isinstance(text_or_series, str):\n",
    "        return normalize_whitespace(normalize_unicode(remove_non_ascii(remove_punctuation_except_commas_periods(remove_emojis(remove_control_characters(remove_emails(remove_urls(remove_html_tags(text)))))))))\n",
    "    else:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = data\n",
    "data_preprocessed['merged_summary_description'] = preprocessor(data['merged_summary_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preprocessed.to_excel(\"test_v2.xlsx\", sheet_name=\"Sheet1\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the cleaned DataFrame to an Excel file\n",
    "# file_path = \"Preprocessed_Cleaned_Data.xlsx\"\n",
    "# data_preprocessed.to_excel(file_path, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data_preprocessed.drop(['priority'], axis=1)  \n",
    "y = data_preprocessed['priority']  \n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying NLP augmentation only to train data\n",
    "##### This section should be commented out based on the approach - without NLP augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_NLP = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_for_NLP['priority'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_minority_class(df, text_column, label_column, aug_n=1):\n",
    "    \"\"\"\n",
    "    Augment text samples of the minority class using synonyms.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset with text and labels.\n",
    "        text_column (str): Name of the column containing text data.\n",
    "        label_column (str): Name of the column containing class labels.\n",
    "        aug_n (int): Number of augmented samples to create per row.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Original dataset appended with augmented samples.\n",
    "    \"\"\"\n",
    "    # Identify the minority class\n",
    "    minority_class = df[label_column].value_counts().idxmin()\n",
    "\n",
    "    # Filter rows belonging to the minority class\n",
    "    minority_class_rows = df[df[label_column] == minority_class]\n",
    "\n",
    "    # Initialize synonym augmenter\n",
    "    synonym_aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "    augmented_rows = []\n",
    "\n",
    "    def dynamic_synonym_augmentation(sentence, n=1):\n",
    "        \"\"\"\n",
    "        Perform synonym-based augmentation with dynamic word count.\n",
    "\n",
    "        Args:\n",
    "            text (str): Input text to augment.\n",
    "            n (int): Number of augmented samples to generate.\n",
    "\n",
    "        Returns:\n",
    "            list: List of augmented text samples.\n",
    "        \"\"\"\n",
    "        # Tokenize the sentence into words\n",
    "        words = sentence.split()\n",
    "        num_words = len(words)\n",
    "\n",
    "        # Dynamically set the maximum number of words to augment\n",
    "        if num_words <= 3:\n",
    "            aug_max = 1  # Augment at most 1 word for short texts\n",
    "        elif num_words <= 20:\n",
    "            aug_max = max(1, int(0.2 * num_words))  # Augment 20% of words for medium-length texts\n",
    "        else:\n",
    "            aug_max = max(1, int(0.1 * num_words))  # Augment 10% of words for long texts\n",
    "\n",
    "        # Update the augmenter with dynamic `aug_max`\n",
    "        synonym_aug.aug_max = aug_max\n",
    "\n",
    "\n",
    "# Generate multiple augmented versions\n",
    "        augmented_sentences = synonym_aug.augment(sentence, n=n)\n",
    "        return augmented_sentences\n",
    "\n",
    "    # Loop through each row in the minority class\n",
    "    for i in minority_class_rows.index:\n",
    "        original_row = df.loc[i].copy()  # Get the original row as a Series\n",
    "\n",
    "        # Augment the text column\n",
    "        original_text = original_row[text_column]\n",
    "        augmented_versions = dynamic_synonym_augmentation(original_text, n=aug_n)\n",
    "\n",
    "        # Create new rows for each augmented version\n",
    "        for aug_text in augmented_versions:\n",
    "            augmented_row = original_row.copy()  # Copy the original row\n",
    "            augmented_row[text_column] = aug_text  # Replace only the text column\n",
    "            augmented_rows.append(augmented_row)\n",
    "\n",
    "    # Convert augmented rows to a DataFrame\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "\n",
    "    # Combine original data with augmented data\n",
    "    combined_df = pd.concat([df, augmented_df], ignore_index=True)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_NLP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Augmented_Train_Data = augment_minority_class(train_data_for_NLP, text_column='merged_summary_description', label_column='priority', aug_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Augmented_Train_Data['priority'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_Augmented = Augmented_Train_Data.drop(['priority'], axis=1)\n",
    "y_Train_Augmented = Augmented_Train_Data['priority']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_Augmented['merged_summary_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_Train_Augmented.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def generate_sentence_embeddings(text, tokenizer, model, max_length=512):\n",
    "    \"\"\"\n",
    "    Generates sentence-level embeddings for a given text by averaging token embeddings.\n",
    "    \"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)  # Split text into sentences\n",
    "    sentence_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence in sentences:\n",
    "            inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length)\n",
    "            outputs = model(**inputs)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            sentence_embeddings.append(cls_embedding)\n",
    "\n",
    "    if sentence_embeddings:  # Check if any sentences were found\n",
    "        return np.mean(np.vstack(sentence_embeddings), axis=0)  # Average embeddings\n",
    "    else:\n",
    "        # Return zero vector if no sentences found\n",
    "        return np.zeros(model.config.hidden_size)\n",
    "\n",
    "def generate_bert_embeddings(texts, tokenizer, model, batch_size=32, max_length=512, sentence_level=False):\n",
    "    \"\"\"\n",
    "    Generate BERT embeddings for a batch of texts.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            batch_embeddings = []\n",
    "\n",
    "            for text in batch:\n",
    "                if sentence_level:\n",
    "                    embedding = generate_sentence_embeddings(text, tokenizer, model, max_length)\n",
    "                else:\n",
    "                    # Generate CLS embeddings\n",
    "                    inputs = tokenizer(\n",
    "                        text,\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=max_length,\n",
    "                        return_tensors=\"pt\"\n",
    "                    )\n",
    "                    outputs = model(**inputs)\n",
    "                    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "                    batch_embeddings.append(cls_embedding)\n",
    "\n",
    "            embeddings.extend(batch_embeddings)\n",
    "\n",
    "    # Stack into a single array\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')\n",
    "bert_model = AutoModel.from_pretrained('microsoft/codebert-base')\n",
    "\n",
    "# Generate embeddings for training and test sets\n",
    "train_texts = X_train['merged_summary_description'].tolist()\n",
    "test_texts = X_test['merged_summary_description'].tolist()\n",
    "\n",
    "train_embeddings = generate_bert_embeddings(train_texts, tokenizer, bert_model)\n",
    "test_embeddings = generate_bert_embeddings(test_texts, tokenizer, bert_model)\n",
    "\n",
    "# Save embeddings to files\n",
    "np.save('Bert_train_embeddings.npy', train_embeddings)\n",
    "np.save('Bert_test_embeddings.npy', test_embeddings)\n",
    "# pickle.dump(y_train, open('y_train.pkl', 'wb'))\n",
    "# pickle.dump(y_test, open('y_test.pkl', 'wb'))\n",
    "tokenizer.save_pretrained(r'C:\\Users\\buket\\Desktop\\Theisis\\BERT_files')\n",
    "bert_model.save_pretrained(r'C:\\Users\\buket\\Desktop\\Theisis\\BERT_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and print the shapes of the embeddings\n",
    "print(\"Shape of train_embeddings:\", train_embeddings.shape)\n",
    "print(\"Shape of test_embeddings:\", test_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_embeddings = np.load('Bert_train_embeddings.npy')\n",
    "test_embeddings = np.load('Bert_test_embeddings.npy')\n",
    "\n",
    "print(\"Train Embeddings Shape:\", train_embeddings.shape)\n",
    "print(\"Test Embeddings Shape:\", test_embeddings.shape)\n",
    "\n",
    "# Check if the number of embeddings matches the number of samples\n",
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of test samples:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining BERT Embeddings with Preprocessed Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the preprocessing pipeline for numerical and categorical features\n",
    "numerical_features = ['bug_age', 'severity_mapped']\n",
    "categorical_features = ['product']\n",
    "\n",
    "# Numerical transformations\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Categorical transformations\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # sparse=False returns a dense array\n",
    "\n",
    "# Apply transformations using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, numerical_features),\n",
    "        ('cat', ohe, categorical_features)\n",
    "    ])\n",
    "\n",
    "# 2. Fit and transform the training data\n",
    "X_train_numerical = X_train[numerical_features]\n",
    "X_test_numerical = X_test[numerical_features]\n",
    "\n",
    "# Fit and transform numerical features\n",
    "numerical_features_train = scaler.fit_transform(X_train_numerical)\n",
    "numerical_features_test = scaler.transform(X_test_numerical)\n",
    "\n",
    "# Apply OneHotEncoder to the categorical 'product' feature\n",
    "categorical_features_train = ohe.fit_transform(X_train[categorical_features])\n",
    "categorical_features_test = ohe.transform(X_test[categorical_features])\n",
    "\n",
    "# 3. Concatenate the embeddings with transformed numerical and categorical features\n",
    "X_train_combined = np.hstack((train_embeddings, numerical_features_train, categorical_features_train))\n",
    "X_test_combined = np.hstack((test_embeddings, numerical_features_test, categorical_features_test))\n",
    "\n",
    "# Now X_train_combined and X_test_combined include BERT embeddings, numerical, and categorical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_combined \n",
    "y_train = y_train \n",
    "\n",
    "X_test = X_test_combined \n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Model-Based Methods for Addressing Class Imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"results_bert_NoNLP_none\", exist_ok=True) \n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [100, 300],  \n",
    "            'classifier__max_depth': [None, 10],  \n",
    "            'classifier__min_samples_split': [5, 10], \n",
    "            'classifier__min_samples_leaf': [1, 4],  \n",
    "            'classifier__max_features': ['sqrt'],  \n",
    "            'classifier__bootstrap': [True],  \n",
    "            'classifier__criterion': ['gini', 'entropy']  \n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(eval_metric=\"mlogloss\", random_state=42, \n",
    "                               objective='multi:softmax', num_class=3),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [100, 300],  \n",
    "            'classifier__max_depth': [6, 15],  \n",
    "            'classifier__learning_rate': [0.01, 0.1],  \n",
    "            'classifier__subsample': [0.6, 0.8],  \n",
    "            'classifier__colsample_bytree': [0.8, 1.0], \n",
    "            'classifier__gamma': [0, 0.1, 0.2],  \n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, class_weight='balanced', \n",
    "                                    multi_class='multinomial', max_iter=1000),\n",
    "        'param_grid': {\n",
    "            'classifier__C': [0.1, 1, 10],  \n",
    "            'classifier__penalty': ['l2'],  \n",
    "            'classifier__solver': ['lbfgs'],  \n",
    "            'classifier__max_iter': [500, 1000],  \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Loop through classifiers and perform GridSearchCV\n",
    "for name, config in classifiers.items():\n",
    "    print(f\"Training and tuning {name}...\")\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', config['model'])\n",
    "    ])\n",
    "    \n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=config['param_grid'],\n",
    "        scoring='f1_macro',  \n",
    "        cv=2,  \n",
    "        verbose=2,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best parameters and evaluation\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred, digits=3)\n",
    "    print(f\"\\nResults for {name} :\\n\")\n",
    "    print(report)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "        \n",
    "    # Save the model\n",
    "    model_filename = f\"results_bert_NoNLP_none/_{name}_model.pkl\"\n",
    "    with open(model_filename, 'wb') as model_file:\n",
    "        pickle.dump(best_model, model_file)\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "        \n",
    "     # Save the classification report\n",
    "    report_filename = f\"results_bert_NoNLP_none/_{name}_report.txt\"\n",
    "    with open(report_filename, 'w') as report_file:\n",
    "        report_file.write(f\"Resampling Technique: \\n\")\n",
    "        report_file.write(f\"Classifier: {name}\\n\")\n",
    "        report_file.write(f\"Best Parameters: {grid_search.best_params_}\\n\\n\")\n",
    "        report_file.write(\"Classification Report:\\n\")\n",
    "        report_file.write(report)\n",
    "    print(f\"Classification report saved to {report_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Resampling Techniques Applied for Adressing Class Imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"results_bert_NoNLP\", exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Corrected definition for resamplers\n",
    "resamplers = {\n",
    "    'SMOTE': SMOTE(sampling_strategy={0: 5000, 1: 5800, 2: 7072}, k_neighbors=5, random_state=42),\n",
    "    \n",
    "    # For SMOTETomek, pass the SMOTE instance as an argument (Tomek Links is applied automatically)\n",
    "    'SMOTETomek': SMOTETomek(smote=SMOTE(sampling_strategy={0: 5000, 1: 5800, 2: 7072}, k_neighbors=5, random_state=42), random_state=42),\n",
    "    \n",
    "    # Tomek Links - no need for sampling_strategy for this since it's handled automatically\n",
    "    'Tomek Links': TomekLinks(sampling_strategy='auto'),\n",
    "}\n",
    "\n",
    "# Define classifiers and parameter grids\n",
    "classifiers = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [100, 300], \n",
    "            'classifier__max_depth': [None, 10],  \n",
    "            'classifier__min_samples_split': [5, 10],  \n",
    "            'classifier__min_samples_leaf': [1, 4],  \n",
    "            'classifier__max_features': ['sqrt'], \n",
    "            'classifier__bootstrap': [True],  \n",
    "            'classifier__criterion': ['gini', 'entropy'] \n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(random_state=42, objective='multi:softmax', num_class=3),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [100, 300],  \n",
    "            'classifier__max_depth': [6, 15],  \n",
    "            'classifier__learning_rate': [0.01, 0.1], \n",
    "            'classifier__subsample': [0.6, 0.8], \n",
    "            'classifier__colsample_bytree': [0.8, 1.0], \n",
    "            'classifier__gamma': [0, 0.1, 0.2],  \n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, multi_class='multinomial', max_iter=1000),\n",
    "        'param_grid': {\n",
    "            'classifier__C': [0.1, 1, 10],  \n",
    "            'classifier__penalty': ['l2'],  \n",
    "            'classifier__solver': ['lbfgs'],  \n",
    "            'classifier__max_iter': [500, 1000], \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Loop through resampling techniques\n",
    "for resampler_name, resampler in resamplers.items():\n",
    "    print(f\"\\nUsing Resampling Technique: {resampler_name}\")\n",
    "    \n",
    "    # Display class distribution before resampling\n",
    "    print(f\"Class distribution before resampling: {Counter(y_train)}\")\n",
    "    \n",
    "    # Loop through classifiers\n",
    "    for name, config in classifiers.items():\n",
    "        print(f\"\\nTraining and tuning {name} with {resampler_name}...\")\n",
    "        \n",
    "        # Create pipeline with resampling integrated\n",
    "        pipeline = ImbPipeline([\n",
    "            ('resampler', resampler),\n",
    "            ('classifier', config['model']),\n",
    "        ])\n",
    "        \n",
    "        # GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=config['param_grid'],\n",
    "            scoring='f1_macro',\n",
    "            cv=3,\n",
    "            verbose=2,\n",
    "            n_jobs=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "         \n",
    "        # Evaluate the model\n",
    "        print(f\"Best parameters for {name} with {resampler_name}: {grid_search.best_params_}\")\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_test, y_pred, digits=3)\n",
    "        print(f\"\\nResults for {name} with {resampler_name}:\\n\")\n",
    "        print(report)\n",
    "        \n",
    "        # Save the model\n",
    "        model_filename = f\"results_bert_NoNLP/{resampler_name}_{name}_model.pkl\"\n",
    "        with open(model_filename, 'wb') as model_file:\n",
    "            pickle.dump(best_model, model_file)\n",
    "        print(f\"Model saved to {model_filename}\")\n",
    "        \n",
    "        # Save the classification report\n",
    "        report_filename = f\"results_bert_NoNLP/{resampler_name}_{name}_report.txt\"\n",
    "        with open(report_filename, 'w') as report_file:\n",
    "            report_file.write(f\"Resampling Technique: {resampler_name}\\n\")\n",
    "            report_file.write(f\"Classifier: {name}\\n\")\n",
    "            report_file.write(f\"Best Parameters: {grid_search.best_params_}\\n\\n\")\n",
    "            report_file.write(\"Classification Report:\\n\")\n",
    "            report_file.write(report)\n",
    "        print(f\"Classification report saved to {report_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
