{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "import unicodedata\n",
    "import os\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup  \n",
    "import emoji \n",
    "import nlpaug.augmenter.word as naw  \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\buket\\Desktop\\new_v1\\Bug_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to Large Dataset to Prevent Kernel Crash Code Below Can Be Used/ If No Needed Should Be Commented Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #In case of a kernel crash : \n",
    "# # Define the reduction percentage\n",
    "# reduction_percentage = 0.2\n",
    "\n",
    "# # Function to reduce the dataset size by class in the target column in place\n",
    "# def reduce_dataset_inplace(data, target_column, reduction_percentage):\n",
    "#     frames = []\n",
    "#     for class_label in data[target_column].unique():\n",
    "#         class_data = data[data[target_column] == class_label]\n",
    "#         sample_size = int(len(class_data) * (1 - reduction_percentage))\n",
    "#         reduced_class_data = class_data.sample(n=sample_size, random_state=42)\n",
    "#         frames.append(reduced_class_data)\n",
    "#     return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# # Reduce the dataset in place\n",
    "# data = reduce_dataset_inplace(data, target_column=\"priority\", reduction_percentage=reduction_percentage)\n",
    "\n",
    "# # View the distribution of the 'priority' column after reduction\n",
    "# priority_distribution = data[\"priority\"].value_counts()\n",
    "\n",
    "# # Print the priority distribution\n",
    "# print(\"Priority column distribution after reduction:\")\n",
    "# print(priority_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priority Column Preprocessing\n",
    "##### Based on the approach Mapping should be changed and data = data[data['priority'] != 'P3'] should be dropped or kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping logic\n",
    "data = data[data['priority'] != '--'] #always drop '--'\n",
    "data = data[data['priority'] != 'P3'] \n",
    "priority_mapping = {\n",
    "    'P1': 0,  \n",
    "    'P2': 0,  \n",
    "    'P4': 1,  \n",
    "    'P5': 2   \n",
    "}\n",
    "\n",
    "\n",
    "data['priority'] = data['priority'].map(priority_mapping)\n",
    "\n",
    "print(data['priority'].value_counts())\n",
    "\n",
    "unique_count = data['priority'].nunique()\n",
    "print(f\"Number of unique values: {unique_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing and Categorical Values in Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['severity'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['severity'].value_counts(dropna=False))\n",
    "\n",
    "# Drop rows with NaN values in the 'severity' column\n",
    "data = data.dropna(subset=['severity'])\n",
    "\n",
    "print(data['severity'].value_counts())\n",
    "print(f\"Updated dataset shape: {data.shape}\")\n",
    "\n",
    "# Severity mapping based on the website\n",
    "severity_mapping = {\n",
    "    'S2': 2,       # Major\n",
    "    'S1': 1,       # Critical\n",
    "    'S3': 3,       # Normal\n",
    "    'S4': 4,       # Minor\n",
    "    'normal': 3,   # Normal\n",
    "    'major': 2,    # Major\n",
    "    'minor': 4,    # Minor\n",
    "    'critical': 1, # Critical\n",
    "    'trivial': 4,  # Minor\n",
    "    'blocker': 1   # Critical\n",
    "}\n",
    "\n",
    "data['severity_mapped'] = data['severity'].map(severity_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['priority'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[['severity', 'severity_mapped']].head())\n",
    "\n",
    "print(data['severity_mapped'].unique())\n",
    "print(data['severity_mapped'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting and Extracting Features from Creation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'creation_time' to datetime\n",
    "data['creation_time'] = pd.to_datetime(data['creation_time'])\n",
    "\n",
    "print(data['creation_time'].head())\n",
    "print(data['creation_time'].dtypes)\n",
    "\n",
    "# Get the maximum creation time from the dataset as the reference date\n",
    "reference_date = data['creation_time'].max()\n",
    "print(f\"Reference date: {reference_date}\")\n",
    "\n",
    "# Calculate bug age in days\n",
    "data['bug_age'] = (reference_date - data['creation_time']).dt.days\n",
    "print(data[['creation_time', 'bug_age']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Product Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_counts = data['product'].value_counts()\n",
    "\n",
    "# Define the threshold for grouping smaller categories\n",
    "threshold = 100\n",
    "data['product'] = data['product'].apply(lambda x: x if product_counts[x] >= threshold else 'Other')\n",
    "\n",
    "# Recalculate value counts after grouping smaller categories\n",
    "updated_product_counts = data['product'].value_counts()\n",
    "\n",
    "# Percentage of bugs grouped under \"Other\"\n",
    "other_percentage = (updated_product_counts['Other'] / len(data)) * 100\n",
    "\n",
    "updated_product_counts, other_percentage\n",
    "\n",
    "unique_count = data['product'].nunique()\n",
    "print(f\"Number of unique values: {unique_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Textual Columns\n",
    "##### Not dropping the missing values in the description column here since they will be merged with the summary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Missing values in 'description': {data['description'].isnull().sum()}\")\n",
    "data['description'] = data['description'].fillna('')\n",
    "print(f\"Missing values in 'description': {data['description'].isnull().sum()}\")\n",
    "\n",
    "# Merge the 'summary' and 'description' columns\n",
    "data['merged_summary_description'] = data['summary'] + \" \" + data['description']\n",
    "\n",
    "# Verify the new column\n",
    "print(data[['summary', 'description', 'merged_summary_description']].head())\n",
    "\n",
    "print(f\"Missing values in 'merged_summary_description': {data['merged_summary_description'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns\n",
    "data = data.drop(['summary', 'creation_time', 'id', 'description', 'severity'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning: Replacing Contractions and Removing Special Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Replacing Contractions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regular expression pattern with replacements\n",
    "def replace_contractions(text):\n",
    "    contractions = {\n",
    "        r\"don´t\": \"do not\",\n",
    "        r\"isn´t\": \"is not\",\n",
    "        r\"hasn´t\": \"has not\",\n",
    "        r\"doesn´t\": \"does not\",\n",
    "        r\"haven´t\": \"have not\",\n",
    "        r\"aren´t\": \"are not\",\n",
    "        r\"couldn´t\": \"could not\",\n",
    "        r\"can´t\": \"can not\"\n",
    "    }\n",
    "    # Compile a regex pattern\n",
    "    pattern = re.compile(\"|\".join(contractions.keys()), flags=re.IGNORECASE)\n",
    "    return pattern.sub(lambda x: contractions[x.group().lower()], text)\n",
    "\n",
    "# Apply the function to the DataFrame column\n",
    "data['merged_summary_description'] = data['merged_summary_description'].apply(replace_contractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cleaning Special Characters and Numbers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning functions\n",
    "def remove_html_tags(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_urls(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "\n",
    "def remove_emails(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return re.sub(r\"[a-zA-Z0-9\\.\\-+_]+@[a-zA-Z0-9\\.\\-+_]+\\.[a-zA-Z]+\",'',text)\n",
    "\n",
    "def remove_control_characters(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return emoji.replace_emoji(text, replace=\"\")\n",
    "\n",
    "def remove_punctuation_except_commas_periods(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    translator = str.maketrans('', '', string.punctuation.replace(\",\", \"\").replace(\".\", \"\"))\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return ''.join(i for i in text if ord(i)<128)\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return unicodedata.normalize('NFKC', text)\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def preprocessor(text_or_series):\n",
    "    if isinstance(text_or_series, pd.Series):\n",
    "        return text_or_series.apply(lambda text: normalize_whitespace(normalize_unicode(remove_non_ascii(remove_punctuation_except_commas_periods(remove_emojis(remove_control_characters(remove_emails(remove_urls(remove_html_tags(str(text)))))))))))\n",
    "    elif isinstance(text_or_series, str):\n",
    "        return normalize_whitespace(normalize_unicode(remove_non_ascii(remove_punctuation_except_commas_periods(remove_emojis(remove_control_characters(remove_emails(remove_urls(remove_html_tags(text)))))))))\n",
    "    else:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = data\n",
    "data_preprocessed['merged_summary_description'] = preprocessor(data['merged_summary_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preprocessed.to_excel(\"test_v2.xlsx\", sheet_name=\"Sheet1\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the cleaned DataFrame to an Excel file\n",
    "# file_path = \"Preprocessed_Cleaned_Data.xlsx\"\n",
    "# data_preprocessed.to_excel(file_path, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data_preprocessed.drop(['priority'], axis=1)  # Adjust 'target' to your actual target column name\n",
    "y = data_preprocessed['priority']  # Replace 'target' with the actual column name of your target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Output shapes for verification\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying NLP augmentation only to train data\n",
    "##### This section should be commented out based on the approach - without NLP augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_NLP = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_for_NLP['priority'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_minority_class(df, text_column, label_column, aug_n=1):\n",
    "    \"\"\"\n",
    "    Augment text samples of the minority class using synonyms.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset with text and labels.\n",
    "        text_column (str): Name of the column containing text data.\n",
    "        label_column (str): Name of the column containing class labels.\n",
    "        aug_n (int): Number of augmented samples to create per row.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Original dataset appended with augmented samples.\n",
    "    \"\"\"\n",
    "    # Identify the minority class\n",
    "    minority_class = df[label_column].value_counts().idxmin()\n",
    "\n",
    "    # Filter rows belonging to the minority class\n",
    "    minority_class_rows = df[df[label_column] == minority_class]\n",
    "\n",
    "    # Initialize synonym augmenter\n",
    "    synonym_aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "    augmented_rows = []\n",
    "\n",
    "    def dynamic_synonym_augmentation(sentence, n=1):\n",
    "        \"\"\"\n",
    "        Perform synonym-based augmentation with dynamic word count.\n",
    "\n",
    "        Args:\n",
    "            text (str): Input text to augment.\n",
    "            n (int): Number of augmented samples to generate.\n",
    "\n",
    "        Returns:\n",
    "            list: List of augmented text samples.\n",
    "        \"\"\"\n",
    "        # Tokenize the sentence into words\n",
    "        words = sentence.split()\n",
    "        num_words = len(words)\n",
    "\n",
    "        # Dynamically set the maximum number of words to augment\n",
    "        if num_words <= 3:\n",
    "            aug_max = 1  # Augment at most 1 word for short texts\n",
    "        elif num_words <= 20:\n",
    "            aug_max = max(1, int(0.2 * num_words))  # Augment 20% of words for medium-length texts\n",
    "        else:\n",
    "            aug_max = max(1, int(0.1 * num_words))  # Augment 10% of words for long texts\n",
    "\n",
    "        # Update the augmenter with dynamic `aug_max`\n",
    "        synonym_aug.aug_max = aug_max\n",
    "\n",
    "\n",
    "# Generate multiple augmented versions\n",
    "        augmented_sentences = synonym_aug.augment(sentence, n=n)\n",
    "        return augmented_sentences\n",
    "\n",
    "    # Loop through each row in the minority class\n",
    "    for i in minority_class_rows.index:\n",
    "        original_row = df.loc[i].copy()  # Get the original row as a Series\n",
    "\n",
    "        # Augment the text column\n",
    "        original_text = original_row[text_column]\n",
    "        augmented_versions = dynamic_synonym_augmentation(original_text, n=aug_n)\n",
    "\n",
    "        # Create new rows for each augmented version\n",
    "        for aug_text in augmented_versions:\n",
    "            augmented_row = original_row.copy()  # Copy the original row\n",
    "            augmented_row[text_column] = aug_text  # Replace only the text column\n",
    "            augmented_rows.append(augmented_row)\n",
    "\n",
    "    # Convert augmented rows to a DataFrame\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "\n",
    "    # Combine original data with augmented data\n",
    "    combined_df = pd.concat([df, augmented_df], ignore_index=True)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_for_NLP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Augmented_Train_Data = augment_minority_class(train_data_for_NLP, text_column='merged_summary_description', label_column='priority', aug_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Augmented_Train_Data['priority'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_Augmented = Augmented_Train_Data.drop(['priority'], axis=1)\n",
    "y_Train_Augmented = Augmented_Train_Data['priority']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_Augmented['merged_summary_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_Train_Augmented.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_Train_Augmented\n",
    "X_test=X_test\n",
    "y_train = y_Train_Augmented\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning The BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine train and test datasets\n",
    "# feature_data = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "# # Combine labels if needed\n",
    "# label_data = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "# # Verify the result\n",
    "# print(feature_data.shape)\n",
    "# print(label_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the data into train and validation sets\n",
    "# # train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "# #     feature_data['merged_summary_description'], \n",
    "# #     label_data, \n",
    "# #     test_size=0.2, \n",
    "# #     stratify=label_data, \n",
    "# #     random_state=42\n",
    "# # )\n",
    "\n",
    "# train_texts = X_train['merged_summary_description']\n",
    "# train_labels = y_train\n",
    "\n",
    "# val_texts = X_test['merged_summary_description']\n",
    "# val_labels = y_test\n",
    "\n",
    "# # Create Hugging Face Dataset objects\n",
    "# train_dataset = Dataset.from_dict({\n",
    "#     'text': train_texts.tolist(),\n",
    "#     'label': train_labels.tolist()\n",
    "# })\n",
    "\n",
    "# val_dataset = Dataset.from_dict({\n",
    "#     'text': val_texts.tolist(),\n",
    "#     'label': val_labels.tolist()\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# # Load BERT tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Tokenization function\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "# # Tokenize datasets\n",
    "# train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "# val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# # Set dataset format for PyTorch\n",
    "# train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "# val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_labels = data_preprocessed['priority'].nunique()\n",
    "# print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# # Define the number of labels (classes)\n",
    "# num_labels = data_preprocessed['priority'].nunique()\n",
    "\n",
    "# # Load the model\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# # Define training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./bert-finetuned\",          # Directory to save the model\n",
    "#     evaluation_strategy=\"epoch\",           # Evaluate every epoch\n",
    "#     save_strategy=\"epoch\",                 # Save checkpoint every epoch\n",
    "#     logging_dir=\"./logs\",                  # Directory for logs\n",
    "#     logging_steps=10,                      # Log every 10 steps\n",
    "#     per_device_train_batch_size=16,        # Batch size for training\n",
    "#     per_device_eval_batch_size=32,         # Batch size for evaluation\n",
    "#     num_train_epochs=3,                    # Number of epochs\n",
    "#     learning_rate=5e-5,                    # Learning rate\n",
    "#     weight_decay=0.01,                     # Weight decay\n",
    "#     save_total_limit=2,                    # Limit the number of saved checkpoints\n",
    "#     seed=42,                               # Random seed\n",
    "#     load_best_model_at_end=True            # Load the best model at the end of training\n",
    "# )\n",
    "\n",
    "# # Define the Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"./bert-finetuned\")\n",
    "# tokenizer.save_pretrained(\"./bert-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate on validation set\n",
    "# results = trainer.evaluate()\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModel\n",
    "\n",
    "# # Load the fine-tuned model\n",
    "# fine_tuned_model = AutoModel.from_pretrained(\"./bert-finetuned\")\n",
    "\n",
    "# Generate embeddings as before using your `generate_bert_embeddings` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./bert-finetuned\")\n",
    "\n",
    "# # Define your function to generate embeddings\n",
    "# def generate_bert_embeddings(texts, tokenizer, model, batch_size=32, max_length=512):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     embeddings = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for i in range(0, len(texts), batch_size):\n",
    "#             batch = texts[i:i + batch_size]\n",
    "#             inputs = tokenizer(\n",
    "#                 batch,\n",
    "#                 padding=True,\n",
    "#                 truncation=True,\n",
    "#                 max_length=max_length,\n",
    "#                 return_tensors=\"pt\"\n",
    "#             )\n",
    "#             outputs = model(**inputs)\n",
    "#             cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # CLS token embeddings\n",
    "#             embeddings.extend(cls_embeddings)\n",
    "\n",
    "#     return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert datasets to lists\n",
    "# train_texts = X_train['merged_summary_description'].tolist()\n",
    "# test_texts = X_test['merged_summary_description'].tolist()\n",
    "\n",
    "# # Generate embeddings\n",
    "# train_embeddings = generate_bert_embeddings(train_texts, tokenizer, fine_tuned_model)\n",
    "# test_embeddings = generate_bert_embeddings(test_texts, tokenizer, fine_tuned_model)\n",
    "\n",
    "# # Check shapes\n",
    "# print(\"Train embeddings shape:\", train_embeddings.shape)\n",
    "# print(\"Test embeddings shape:\", test_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Save train and test embeddings to .npy files\n",
    "# np.save('finetuned_train_embeddings.npy', train_embeddings)\n",
    "# np.save('finetuned_test_embeddings.npy', test_embeddings)\n",
    "\n",
    "# print(\"Embeddings saved to 'train_embeddings.npy' and 'test_embeddings.npy'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_embeddings = np.load('finetuned_train_embeddings.npy')\n",
    "test_embeddings = np.load('finetuned_test_embeddings.npy')\n",
    "\n",
    "print(\"Train Embeddings Shape:\", train_embeddings.shape)\n",
    "print(\"Test Embeddings Shape:\", test_embeddings.shape)\n",
    "\n",
    "# Check if the number of embeddings matches the number of samples\n",
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of test samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Embeddings with Preprocessed Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the preprocessing pipeline for numerical and categorical features\n",
    "numerical_features = ['bug_age', 'severity_mapped']\n",
    "categorical_features = ['product']\n",
    "\n",
    "# Numerical transformations\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Categorical transformations\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # sparse=False returns a dense array\n",
    "\n",
    "# Apply transformations using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, numerical_features),\n",
    "        ('cat', ohe, categorical_features)\n",
    "    ])\n",
    "\n",
    "# 2. Fit and transform the training data\n",
    "X_train_numerical = X_train[numerical_features]\n",
    "X_test_numerical = X_test[numerical_features]\n",
    "\n",
    "# Fit and transform numerical features\n",
    "numerical_features_train = scaler.fit_transform(X_train_numerical)\n",
    "numerical_features_test = scaler.transform(X_test_numerical)\n",
    "\n",
    "# Apply OneHotEncoder to the categorical 'product' feature\n",
    "categorical_features_train = ohe.fit_transform(X_train[categorical_features])\n",
    "categorical_features_test = ohe.transform(X_test[categorical_features])\n",
    "\n",
    "# 3. Concatenate the embeddings with transformed numerical and categorical features\n",
    "X_train_combined = np.hstack((train_embeddings, numerical_features_train, categorical_features_train))\n",
    "X_test_combined = np.hstack((test_embeddings, numerical_features_test, categorical_features_test))\n",
    "\n",
    "# Now X_train_combined and X_test_combined include BERT embeddings, numerical, and categorical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_combined\n",
    "X_test = X_test_combined\n",
    "y_train = y_Train_Augmented\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Model-Based Methods for Addressing Class Imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results_finetuned_bert_uncased_none\", exist_ok=True)  # Create a folder to save results\n",
    "\n",
    "\n",
    "# Define classifiers and their parameter grids\n",
    "classifiers = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [100, 200, 300],  \n",
    "            'classifier__max_depth': [None, 10],  \n",
    "            'classifier__min_samples_split': [5, 10], \n",
    "            'classifier__min_samples_leaf': [1, 4],  \n",
    "            'classifier__max_features': ['sqrt'],  \n",
    "            'classifier__bootstrap': [True],  \n",
    "            'classifier__criterion': ['gini', 'entropy']  \n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(eval_metric=\"mlogloss\", random_state=42, \n",
    "                               objective='multi:softmax', num_class=3),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [100, 200, 300],  \n",
    "            'classifier__max_depth': [3, 6, 15],  \n",
    "            'classifier__learning_rate': [0.01, 0.1],  \n",
    "            'classifier__subsample': [0.6, 0.8],  \n",
    "            'classifier__colsample_bytree': [0.8, 1.0], \n",
    "            'classifier__gamma': [0, 0.1, 0.2],  \n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, class_weight='balanced', \n",
    "                                    multi_class='multinomial', max_iter=1000),\n",
    "        'param_grid': {\n",
    "            'classifier__C': [0.1, 1, 10],  \n",
    "            'classifier__penalty': ['l2'],  \n",
    "            'classifier__solver': ['lbfgs'],  \n",
    "            'classifier__max_iter': [500, 1000],  \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through classifiers and perform GridSearchCV\n",
    "for name, config in classifiers.items():\n",
    "    print(f\"Training and tuning {name}...\")\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', config['model'])\n",
    "    ])\n",
    "    \n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=config['param_grid'],\n",
    "        scoring='f1_macro', \n",
    "        cv=3,  \n",
    "        verbose=2,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best parameters and evaluation\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred, digits=3)\n",
    "    print(f\"\\nResults for {name} :\\n\")\n",
    "    print(report)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "        \n",
    "    # Save the model\n",
    "    model_filename = f\"results_finetuned_bert_uncased_none/_{name}_model.pkl\"\n",
    "    with open(model_filename, 'wb') as model_file:\n",
    "        pickle.dump(best_model, model_file)\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "        \n",
    "     # Save the classification report\n",
    "    report_filename = f\"results_finetuned_bert_uncased_none/_{name}_report.txt\"\n",
    "    with open(report_filename, 'w') as report_file:\n",
    "        report_file.write(f\"Resampling Technique: \\n\")\n",
    "        report_file.write(f\"Classifier: {name}\\n\")\n",
    "        report_file.write(f\"Best Parameters: {grid_search.best_params_}\\n\\n\")\n",
    "        report_file.write(\"Classification Report:\\n\")\n",
    "        report_file.write(report)\n",
    "    print(f\"Classification report saved to {report_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Resampling Techniques Applied for Adressing Class Imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"results_finedtuned_bert_uncased_paramgrid\", exist_ok=True)\n",
    "\n",
    "\n",
    "resamplers = {\n",
    "    'SMOTE': SMOTE(sampling_strategy={0: 5000, 1: 5800, 2: 7072}, k_neighbors=5, random_state=42),\n",
    "    \n",
    "    # For SMOTETomek, pass the SMOTE instance as an argument (Tomek Links is applied automatically)\n",
    "    'SMOTETomek': SMOTETomek(smote=SMOTE(sampling_strategy={0: 5000, 1: 5800, 2: 7072}, k_neighbors=5, random_state=42), random_state=42),\n",
    "    \n",
    "    # Tomek Links - no need for sampling_strategy for this since it's handled automatically\n",
    "    'Tomek Links': TomekLinks(sampling_strategy='auto'),\n",
    "}\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [100, 200, 300], \n",
    "            'classifier__max_depth': [None, 10],  \n",
    "            'classifier__min_samples_split': [5, 10],  \n",
    "            'classifier__min_samples_leaf': [1, 4],  \n",
    "            'classifier__max_features': ['sqrt'], \n",
    "            'classifier__bootstrap': [True],  \n",
    "            'classifier__criterion': ['gini', 'entropy'] \n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(random_state=42, objective='multi:softmax', num_class=3),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [100, 200, 300],  \n",
    "            'classifier__max_depth': [3, 6, 15],  \n",
    "            'classifier__learning_rate': [0.01, 0.1], \n",
    "            'classifier__subsample': [0.6, 0.8], \n",
    "            'classifier__colsample_bytree': [0.8, 1.0], \n",
    "            'classifier__gamma': [0, 0.1, 0.2],  \n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, multi_class='multinomial', max_iter=1000),\n",
    "        'param_grid': {\n",
    "            'classifier__C': [0.1, 1, 10],  \n",
    "            'classifier__penalty': ['l2'],  \n",
    "            'classifier__solver': ['lbfgs'],  \n",
    "            'classifier__max_iter': [500, 1000],  \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through resampling techniques\n",
    "for resampler_name, resampler in resamplers.items():\n",
    "    print(f\"\\nUsing Resampling Technique: {resampler_name}\")\n",
    "    \n",
    "    # Display class distribution before resampling\n",
    "    print(f\"Class distribution before resampling: {Counter(y_train)}\")\n",
    "    \n",
    "    # Loop through classifiers\n",
    "    for name, config in classifiers.items():\n",
    "        print(f\"\\nTraining and tuning {name} with {resampler_name}...\")\n",
    "        \n",
    "        # Create pipeline with resampling integrated\n",
    "        pipeline = ImbPipeline([\n",
    "            ('resampler', resampler),\n",
    "            ('classifier', config['model']),\n",
    "        ])\n",
    "        \n",
    "        # GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=config['param_grid'],\n",
    "            scoring='f1_macro',\n",
    "            cv=3,\n",
    "            verbose=2,\n",
    "            n_jobs=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "         \n",
    "        # Evaluate the model\n",
    "        print(f\"Best parameters for {name} with {resampler_name}: {grid_search.best_params_}\")\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_test, y_pred, digits=3)\n",
    "        print(f\"\\nResults for {name} with {resampler_name}:\\n\")\n",
    "        print(report)\n",
    "        \n",
    "        # Save the model\n",
    "        model_filename = f\"results_finedtuned_bert_uncased_paramgrid/{resampler_name}_{name}_model.pkl\"\n",
    "        with open(model_filename, 'wb') as model_file:\n",
    "            pickle.dump(best_model, model_file)\n",
    "        print(f\"Model saved to {model_filename}\")\n",
    "        \n",
    "        # Save the classification report\n",
    "        report_filename = f\"results_finedtuned_bert_uncased_paramgrid/{resampler_name}_{name}_report.txt\"\n",
    "        with open(report_filename, 'w') as report_file:\n",
    "            report_file.write(f\"Resampling Technique: {resampler_name}\\n\")\n",
    "            report_file.write(f\"Classifier: {name}\\n\")\n",
    "            report_file.write(f\"Best Parameters: {grid_search.best_params_}\\n\\n\")\n",
    "            report_file.write(\"Classification Report:\\n\")\n",
    "            report_file.write(report)\n",
    "        print(f\"Classification report saved to {report_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
